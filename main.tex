\documentclass[%
%reprint,
%superscriptaddress,
%groupedaddress,
%unsortedaddress,
%runinaddress,
%frontmatterverbose, 
% preprint,
%preprintnumbers,
 nofootinbib,
%nobibnotes,
%bibnotes,
 amsmath,amssymb,
 aps,
%pra,
%prb,
%rmp,
%prstab,
%prstper,
%floatfix,
 twocolumn
]{revtex4-2}


\usepackage{aas_macros}
\usepackage{amssymb}
\usepackage{amsmath}
\usepackage{array}
\usepackage{color,units}
\usepackage[dvipsnames]{xcolor} % for more colours!
\usepackage{lineno}
\usepackage{dcolumn}
\usepackage{longtable}
\usepackage[normalem]{ulem} %% for striking out text
\usepackage{subfigure}
\usepackage[T1]{fontenc}
\usepackage[breaklinks]{hyperref}
\usepackage{booktabs}
\usepackage{xspace} 
\usepackage{bm}% bold math
\usepackage{graphicx} % Include figure files
\graphicspath{{images/}} %Setting the graphicspath

% symbols
\DeclareSymbolFont{extraup}{U}{zavm}{m}{n}
\DeclareMathSymbol{\varheart}{\mathalpha}{extraup}{86}
\DeclareMathSymbol{\vardiamond}{\mathalpha}{extraup}{87}


% Keywords
\newcommand{\bilby}{{\sc \href{https://lscsoft.docs.ligo.org/bilby/}{\texttt{Bilby}}}\xspace}
\newcommand{\bilbypipe}{{\sc bilby\_pipe}\xspace}
\newcommand{\pbilby}{{\sc pBilby}\xspace}
\newcommand{\dynesty}{{\sc dynesty}\xspace}
\newcommand{\cpnest}{{\sc cpnest}\xspace}
\newcommand{\ptemcee}{{\sc ptemcee}\xspace}
\newcommand{\gwpy}{{\sc \href{https://gwpy.github.io/}{\texttt{GWpy}}}\xspace}
\newcommand{\imrphenomp}{{\sc IMRPhenomPv2}\xspace}
\newcommand{\seob}{{\sc SEOBNRv4PHM}\xspace}
\newcommand{\gstlal}{{\sc GstLAL}\xspace}
\newcommand{\pycbc}{{\sc \href{https://pycbc.org/}{\texttt{PyCBC}}}\xspace}


% math keywords 
\newcommand{\fancytext}[1]{{\relax\ifmmode#1\else $#1$\fi}\xspace}
\newcommand{\mathcmd}[1]{{\sc \relax\ifmmode#1\else $#1$\fi}\xspace}
\newcommand{\bcr}{\mathcmd{\rho_\text{BCR}}}
\newcommand{\pycbcstat}{\mathcmd{\rho_\text{PC}}}
\newcommand{\snr}{\mathcmd{\rho}}
\newcommand{\psd}{\mathcmd{P(f)}}
\newcommand{\msun}{\mathcmd{\text{M}_\odot}}
\newcommand{\parameters}{\mathcmd{\vec{\theta}}}
\newcommand{\prior}{\mathcmd{\pi(\parameters)}}
\newcommand{\template}{\mathcmd{\mu(\parameters)}}
\newcommand{\fap}{\mathcmd{\text{FAP}}}

\newcommand{\pastro}{\fancytext{p_\text{astro}}}
\newcommand{\pastrobcr}{\fancytext{p_\text{astro}^{\text{BCR}}}}
\newcommand{\untunedpastrobcr}{\fancytext{p_\text{astro}^{\text{BCR}\prime}}}
\newcommand{\pastroext}{\fancytext{p_\text{astro}^{\text{ext}}}}
\newcommand{\pval}{\fancytext{\text{p-value}}}
% Table settings
\renewcommand{\aboverulesep}{0pt}
\renewcommand{\belowrulesep}{0pt}
% \setlength\cellspacetoplimit{2pt}
% \setlength\cellspacebottomlimit{2pt}

\newcolumntype{C}{>{\centering\arraybackslash}X}
\newcolumntype{L}{>{\arraybackslash}X}

% Aesthetic colours
\definecolor{dodgerblue}{HTML}{1E90FF}
\definecolor{viennared}{HTML}{DA0A14}
\definecolor{ctorange}{HTML}{FF6C0C}
\definecolor{wales}{HTML}{ff0038}
\definecolor{benettongreen}{HTML}{009421}
\definecolor{valenciacfred}{HTML}{ee3524}
\definecolor{barcelonafcgold}{HTML}{edbb00}
\definecolor{jam}{HTML}{A50B5E}
\definecolor{austriawien}{HTML}{441678}
\definecolor{italia90green}{HTML}{009966}
\definecolor{ferrarired}{HTML}{ff2800}
\definecolor{gray}{HTML}{F0F0F0}
\definecolor{LightCyan}{rgb}{0.88,1,1}
\newcolumntype{a}{>{\columncolor{gray}}c}
\newcolumntype{b}{>{\columncolor{white}}c}

% author comments
\newcommand{\av}[1]{\textcolor{orange}{[AV: #1]}}
\newcommand{\rs}[1]{\textcolor{red}{[RS: #1]}}
\newcommand{\et}[1]{\textcolor{blue}{[ET: #1]}}



% %%% AFFILIATIONS
% %------ affiliation shortcuts
% \newcommand{\SPAno}{1}
% \newcommand{\OzGravMonashno}{2}
% \newcommand{\CITno}{3}
% \newcommand{\MITno}{4}
% \newcommand{\Kavlino}{5}

% %--------------------------
% \newcommand{\SPA}{School of Physics and Astronomy, Monash University, Clayton VIC 3800, Australia}
% \newcommand{\OzGravMonash}{OzGrav: The ARC Centre of Excellence for Gravitational Wave Discovery, Clayton VIC 3800, Australia}
% \newcommand{\MIT}{LIGO Laboratory, Massachusetts Institute of Technology, Cambridge, MA 02139, USA}
% \newcommand{\Kavli}{Department of Physics and Kavli Institute for Astrophysics and Space Research, Massachusetts Institute of Technology, \\ 77 Massachusetts Ave, Cambridge, MA 02139, USA}
% \newcommand{\CIT}{LIGO Laboratory, California Institute of Technology, Pasadena, CA 91125, USA}
% %%%

\begin{document}


\title{A Bayesian ranking statistic to find \\high-mass black holes in LIGO data}

% \author{Author list TBD}
\input{authors}

\date{\today}

\begin{abstract}
The detection of intermediate-mass black holes ( $10^2-10^6$~\msun) will shed light on the formation of supermassive black holes and thus galaxy formation. Although LIGO is sensitive to the merger of binary black holes with total masses up to $400$~\msun, only 4 of their 50 detections have a total mass $>100$~\msun. A possible explanation for the absence of intermediate-mass events may be their misclassification as short-duration instrumental noise transients. Short-duration instrumental transients mimic the short-duration gravitational-wave signals from intermediate-mass binary black hole mergers. Here we demonstrate that a ranking statistic utilising Bayesian inference could be a more sensitive tool for detecting high-mass binary black hole mergers (systems with a total mass $>55$~\msun) compared to a traditional match-filter ranking statistic. We applied this technique on the high-mass triggers during LIGO's second observing run to investigate the possibility of discovering new gravitational-wave signals from high mass black hole binaries and re-calculate the significance of high-mass candidate events. Although our analysis does not discover new gravitational wave events, it does provide a Bayesian measure of various candidates and events. 
\end{abstract}

\maketitle


%%%%%%---SECTIONS---%%%%%%%%%%%%
\section{\label{sec:Introduction}Introduction}

Since the 1970s, there has been an accumulation of evidence for stellar-mass and supermassive black holes. In April 2019, the Event Horizon Telescope provided the first visual evidence of the supermassive black hole M87~\cite{m87photo}. As of January 2021, the LIGO Scientific Collaboration has confirmed $\sim50$ binary black hole systems and listed numerous candidate events~\cite{GWTC1, GWTC2, gracedb}. Additionally, since the public release of LIGO's first and second observing run's data (O1 and O2), several external groups, such as \pycbc~\cite{pycbc_code} and a research team at the Institute for Advanced Study (IAS)~\cite{IAS0, IAS1, IAS2}, have independently searched and identified additional binary black hole gravitational wave candidates. These various discoveries have firmly authenticated the existence of stellar-mass black holes, supermassive black holes and binary black hole systems.

Until recently, there was no definitive evidence for intermediate-mass black holes, the black holes whose masses lie between that of stellar-mass and supermassive black hole systems ($10^2-10^6\ \msun$). This changed with the detection of GW190521, a unique gravitational wave event that led to the formation of a black hole with a mass  $142\ \msun$, the first confirmed direct discovery of an intermediate-mass black hole~\cite{gw190521}. Although this is the first gravitational wave event leading to discovering a black hole with a mass in the intermediate range, ground-based gravitational wave detectors are sensitive to gravitational waves from even more massive systems to systems with a total mass of $400\ \msun$~\cite{GWTC1}. Additionally, gravitational waves from systems with masses greater than $100\ \msun$ systems should occur at a rate of $0-10\text{yr}^{-1}$~\cite{fregeau2006imbhbRatePrediction, mandel2008rates,rodriguez2015bbhRatePredictions,ligo_imbh_search}.  \av{this is surely outdated... get more recent rate quote} Hence, LIGO might have gravitational wave events from more intermediate-mass systems hidden in its data, potentially even in O2 data.

However, even after conducting a targeted matched-filter based search for gravitational waves from intermediate-mass black holes in O2's data, the heaviest total mass detected so far is approximately $80\ \msun$~\cite{GWTC1,imbhbSearch2014, ligo_imbh_search}. A possible explanation for the absence of intermediate-mass events may be due to their misclassification as short-duration instrumental noise transients known as glitches~\cite{ pycbc_short_duration_transients, pe_with_glitch, blip_glitches}. These glitches can mimic astrophysical signals and hence decrease the significance of true gravitational wave events. 

One method to account for glitches while searching for gravitational waves from coalescing compact binaries is by utilising an astrophysical Bayesian odds~\cite{bci, BCR1, BCR2, bcr_gw151216, bayesian_odds}. A true Bayesian odds calculated without using bootstrap techniques can provide events with a more accurate significance that is agnostic to a specific search strategy~\cite{BCR2, bcr_gw151216,  bayesian_odds}. 

Additionally, Bayesian odds can include comprehensive astrophysical information in its calculation. For example, a Bayesian odds to help detect gravitational-wave candidates can incorporate information on if an event's binary system was precessing and if the signal contains higher-order modes and is coherent amongst various detectors. Because of the possibility of Bayesian methods to incorporate detailed physical information about a gravitational wave signal, the LIGO Scientific Collaboration uses Bayesian methods to determine the source parameters of gravitational-wave events~\cite{abbott2016ligo, GWTC1}. This paper demonstrates that the power of Bayesian methods used in parameter estimation can also discriminate between coherent gravitational-wave signals, incoherent glitches, and Gaussian noise in the form of a Bayesian odds, utilised as a ranking statistic. 

In this paper, we utilise a Bayesian method, called the Bayesian Coherence Ratio \bcr~\cite{BCR1}, to rank the candidate gravitational wave signals from high-mass compact binary coalescences (systems with total masses in the range of $55-500\ \msun$) in the detector data recorded during O2. Although the \bcr, utilising bootstrap techniques, does not provide the true Bayesian odds, it provides a more astrophysical measure of candidate events' significance than a traditional match-filter significance.

We find that (a) high-mass events reported in the GWTC-1, including GW170729 (an event with disputed \pastro amongst various search pipelines) have high significance; (b) high-mass events detected from the IAS group have differing levels of significance; and that (c) our ranking statistic does not identify any intermediate-mass black holes, but does identify an unreported stellar-mass binary black hole candidate, 170222.

The remainder of this paper is structured as follows. We outline our methods, including details of the \bcr and the retrieval of our candidate events in Section~\ref{sec:method}. We present details on the implementation of our analysis in Section~\ref{sec:Analysis}. Finally, we present our results in Section~\ref{sec:Results}, and discuss these results in the context of the significance of gravitational wave candidates in Section~\ref{sec:Conclusion}.


\section{Method\label{sec:method}}
The gravitational wave community uses Bayesian inference to perform parameter estimation and model selection. In this work, we utilise Bayesian inference to calculate the significance of high-mass candidate events in O2 by using the \bcr as a ranking statistic, taking a step toward building a unified Bayesian framework to search for candidates and estimate their parameters.

Although a dedicated Bayesian search for gravitational waves, as presented by ~\citet{BCR2}, does not require noise estimation using empirical methods, this Bayesian significance ranking technique utilises \textit{time-slides}. To perform time-slides, data from independent observatories are time-shifted by amounts greater than the light-travel time between the two detectors. Each unique time-slide amount creates an artificial signal-free `background' data set. When search pipelines scan these background data sets for gravitational wave events, they can find \textit{triggers}\footnotemark, even though the background data set should not contain coherent astrophysical signals. These triggers in background data are labelled background triggers, while coherent triggers obtained in non-time-slid data are labelled candidate triggers.

\footnotetext{\textit{Triggers} are points in time when the matched-filter SNR is larger than a threshold value for a given gravitational wave template~\cite{pycbc_og1}.}

Calculating the \bcr ranking statistic for each background trigger builds a background \bcr distribution. With a background distribution,  it is possible to assign a statistical significance of how likely a candidate trigger, detected by the search pipelines over non-time slid data, is due to a gravitational wave signal. 

This section discusses (a) the method to retrieve triggers, and (b) the \bcr and how it is utilised as a ranking statistic to calculate the significance of candidate triggers.


\subsection{Triggers for Analysis}

The LIGO Scientific collaboration operates several search pipelines that scan for gravitational waves from compact binary mergers such as \texttt{GstLAL}, \texttt{MBTA}, \texttt{SPIIR} and \pycbc~\cite{GWTC1}.

The output of \pycbc's search is a list of candidate trigger times and their corresponding \pycbc ranking statistic \pycbcstat. The \pycbcstat statistic is akin to the matched-filter signal-to-noise ratio \snr. However, unlike \snr, \pycbcstat includes some information on the candidate signal's intrinsic and extrinsic properties and other information that feeds into determining if the signal can have astrophysical origins~\cite{pycbc_og6}. The additional physical information incorporated in \pycbcstat makes it a more accurate measure of significance than the standard \snr. 

Whenever a local maximum of $\pycbcstat > \snr_\text{T}$, where $\snr_\text{T}$ is some threshold value, the \pycbc search pipeline produces a single-detector trigger associated with the detector and time where the apparent signal in the data has its merger~\cite{pycbc_og6}.

For \pycbc to consider a trigger to be a \textit{candidate trigger}, a trigger that may be from astrophysical origins, the trigger must be observed between detectors with the same template and a time of arrival difference less than the gravitational-wave travel time~\cite{pycbc_og1}. To test its search, \pycbc also conducts searches for \textit{simulated triggers}, artificial triggers manufactured by injecting signals into the detector data. These simulated signal studies provide \pycbc with metrics on its search's sensitivity. Finally, to quantify the statistical significance of candidate events, \pycbc artificially constructs a \textit{background trigger} set to compare against the candidate events. These background triggers are coherent signal-free events, constructed by applying relative offsets, or time-slides, between the data of different detectors~\cite{pycbc_og6}. The time-slides to generate the background triggers are greater than the gravitational-wave travel time between detectors to ensure that the background triggers are not of astrophysical origins. 

Our work demonstrates that the \bcr can be used in the same way as \pycbcstat to measure candidate triggers' statistical significance.  The \bcr can be a powerful ranking statistic as the \bcr incorporates information of not only all possible binary black hole systems that might have merged to produce the trigger but also the various incoherent glitches that might cause a false-detection. 

Before we discuss how we use the \bcr as a measure of significance, we introduce the method to calculate the \bcr in the following section.


\subsection{The Bayesian Coherence Ratio}

Bayes theorem states that the posterior probability distribution $p(\parameters|d,\mathcal{H})$ for data $d$ and a vector of parameters \parameters that describe a model which quantifies a hypothesis $\mathcal{H}$, is given by
\begin{equation}
p(\parameters|d,\mathcal{H}) = \frac{\mathcal{L}(d|\parameters, \mathcal{H}) \ \pi(\parameters | \mathcal{H})}{\mathcal{Z}(d|\mathcal{H})}\ , 
\end{equation}
where $\mathcal{L}(d|\parameters, \mathcal{H})$ is the likelihood of the data given the parameters \parameters and the hypothesis, $\pi(\parameters | \mathcal{H})$ is the prior probability of the parameters, and finally,
\begin{equation}
    \mathcal{Z}(d|\mathcal{H}) = \int\limits_{\parameters} \ \mathcal{L}(d|\parameters,\mathcal{H}) \ \pi(\parameters | \mathcal{H}) \ d\parameters
\end{equation} is the likelihood after marginalising over the parameters \parameters.  To compare two hypotheses $\mathcal{H}_A$ and $\mathcal{H}_B$ with the Bayes theorem one can calculate an odds ratio
\begin{equation}
    \mathcal{O}^A_B = \frac{\mathcal{Z}^A\ \pi(\parameters^A)}{\mathcal{Z}^B\ \pi(\parameters^B)}\ ,
\end{equation}
where $\mathcal{Z}^A$ and $\mathcal{Z}^B$ are the shorthand for the evidences  $\mathcal{Z}(d|\mathcal{H}_A)$ and $\mathcal{Z}(d|\mathcal{H}_B)$. The odds ratio can tell us which of the two hypotheses is more likely. For example, if $\mathcal{O}^A_B >> 1$, then this odds ratio indicates that the $\mathcal{H}_A$ describes the data much better than $\mathcal{H}_B$. 

The \bcr is a Bayesian odds ratio like the above, of a coherent signal hypotheses $\mathcal{H}_S$ and an incoherent instrumental feature hypothesis $\mathcal{H}_I$ for a network of $D$ detectors. $\mathcal{H_I}$ states that each detector $i$ has either pure Gaussian noise $\mathcal{H}_N$ or a glitch $\mathcal{H}_G$. Following~\citet{BCR1}, the \bcr is given by
\begin{equation}
\label{eq:bcr}
\bcr = \frac{\alpha Z^S}{\prod\limits^D_{i=1} \ [\beta Z^G_i + (1-\beta)Z^N_i]}\ ,
\end{equation}
where $Z^S$, $Z^G_i$ and $Z^N_i$ are the Bayesian evidences (marginalised likelihoods) for $\mathcal{H}_S$, $\mathcal{H}_N$, and $\mathcal{H}_G$. $\alpha$ and $\beta$, are the prior odds for obtaining a signal $\alpha=P(\mathcal{H}_S)/P(\mathcal{H}_I)$ and the prior odds for obtaining a glitch $\beta=P(\mathcal{H}_G)/P(\mathcal{H}_I)$. As the rate of signal and glitches are unknown, these priors $\alpha$ and $\beta$ are tuned to maximise the \bcr distributions for background data (coherent signal-free data) and simulated signals~\cite{BCR1}.  

\subsection{Bayesian Evidence Evaluation}
\subsubsection{Noise Model}
We assume that each detector's noise is Gaussian and stationary over the period being analysed~\cite{ligo_psd}. In practice, we assume that the noise has a mean of zero that the noise variance $\sigma^2$ is proportional to the noise power spectral density (PSD) \psd of the data. Using the \psd, for each data segment $d_i$ in each of the $i$ detectors in a network of $D$ detectors, we can write 
\begin{equation}
\label{eq:zn}
Z^N_i = \mathcal{N}(d_i) = \frac{1}{2\pi \psd_i} \ \text{exp}\left(-\frac{1}{2} \frac{d_i}{\psd_i} \right) \ ,
\end{equation}
where $\mathcal{N}(d_i)$ is a normal distribution with $\mu=0$ and $\sigma^2\sim \psd$. 

\subsubsection{Coherent Signal Model}
We model coherent signal using a binary black hole waveform template \template, where the vector \parameters contains a point in the 15 dimensional space describing precessing binary-black hole mergers. For the signal to be coherent, \parameters must be consistent in each 4-second data segment $d_i$ for a network of $D$ detectors, Hence, the coherent signal evidence is calculated as
\begin{equation}
\label{eq:zs}
Z^S = \int\limits_{\parameters} \prod\limits^{D}_{i=1} \left[ \mathcal{L}(d_i|\template)\right] \pi(\parameters | \mathcal{H}_S)\  \text{d}\parameters \ ,
\end{equation}
where $\pi(\parameters| \mathcal{H}_S)$ is the prior for the parameters in the coherent signal hypothesis, and $\mathcal{L}(d_i|\template))$ is the likelihood for the coherent signal hypothesis that depends on the gravitational wave template \template and its parameters \parameters. 

\subsubsection{Incoherent Glitch Model}
Finally, as glitches are challenging to model and poorly understood, we utilise a surrogate model for glitches: the glitches are modelled using gravitational wave templates  \template with uncorrelated  parameters amongst the different detectors such that  $\parameters_i \neq \parameters_j$ for two detectors $i$ and $j$~\cite{bci}.  Modelling glitches with \template captures the worst case scenario: when glitches appear similar to gravitational wave signals. Thus, we can write $Z^G_i$ as 
\begin{equation}
\label{eq:zg}
Z^G_i = \int\limits_{\parameters} \mathcal{L}(d_i|\template)\ \pi(\parameters| \mathcal{H}_G)\  \text{d}\parameters  \ ,
\end{equation}
where $\pi(\theta| \mathcal{H}_G)$ is the prior for the parameters in the incoherent glitch hypothesis. 

\subsection{Tuning the BCR}

After calculating the \bcr for a set of background triggers and simulated triggers from as stretch of detector-data (a data chunk), we can compute probability distributions for the background and simulated triggers, $p_b(\bcr)$ and $p_s(\bcr)$. We expect the background trigger and simulated signal \bcr values to favour the incoherent glitch and the coherent signal hypothesis, respectively. Ideally, these distributions representing two unique populations should be distinctly separate and have no overlap in their \bcr values. The prior odds parameters $\alpha$ and $\beta$ from Eq.~\ref{eq:bcr} help separate the two distributions. Altering $\alpha$ translates the \bcr probability distributions while adjusting $\beta$ spreads the distributions. Although Bayesian hyper-parameter estimation can determine the optimal values for $\alpha$ and $\beta$, an easier approach is to adjust the parameters for each data chunk's \bcr distribution. In this study, we tune $\alpha$ and $\beta$ to maximally separate the \bcr distributions for the background and simulated triggers. 

To calculate the separation between $p_b(\bcr)$ and $p_s(\bcr)$, we use the Kullback--Leibler divergence (KL divergence) $D_{KL}$, given by
\begin{equation}
    D_{KL}(p_b | p_s) = \sum\limits_{x\in \bcr} p_b(x) \log \left( \frac{p_b(x)}{p_a(x)} \right)  \ .
\end{equation}
The $D_{KL}=0$ when the distributions are identical and increases as the asymmetry between the distributions increases. 

We limit our search for the maximum KL-divergence in the $\alpha$ and $\beta$ ranges of $[10^{-10}, 10^0]$ as values outside this range are nonphysical. We set our values for $\alpha$ and $\beta$ to those which provide the highest KL-divergence and calculate the \bcr for candidate events present in this data chunk. Note that we conduct the analysis in data chunks of a few days rather than an entire data set of a few months as the background may be different at different points of the entire data set.

\subsection{Calculating the Significance of Candidate events}
With the tuned values of $\alpha$ and $\beta$ we can calculate the \bcr for candidate events. As mentioned previously, irrespective of the Bayesian interpretation for \bcr, we treat the \bcr as a traditional detection statistic to obtain a frequentist estimate of the significance of candidate event measured against the time-slid background \bcr distribution. 

We expect the background trigger \bcr values to favour the incoherent glitch hypothesis (the null hypothesis). Candidate event \bcr values will either be statistically insignificant compared to the background triggers, implying the candidate is a glitch, or statistically significant to the background distribution, indicating the possible presence of an astrophysical signal. To quantify the significance level, we can calculate a false alarm probability with trial factors \fap for the candidate events. The \fap is the probability that a candidate event originating from a non-astrophysical source can be is falsely identified as a signal.

To calculate the \fap, consider each candidate \bcr as a single statistical trail that can occur at a fixed false alarm probability $f$, where $f$ is the probability of observing a background $\bcr'$ greater than or equal to the candidate \bcr,
\begin{equation}
    f = \frac{\text{Count of } \bcr' \leq \bcr}{\text{Count of } \bcr'} \ .
\end{equation}
The false alarm probability with trails \fap that the \bcr measurement occurs at least once for $N$ trials $(N > 0)$, where $N$ is the number of candidate triggers, can be written as
\begin{equation}
    \fap = 1 - (1-f)^N \ .
\end{equation}

The \fap can be used to construct a \pastro, the probability that a signal is of astrophysical origin~\cite{pastro_1,pastro_2,pastro_3}
\begin{equation}
    \pastro = 1 -  \fap \ .
\end{equation}


\section{Analysis}\label{sec:Analysis}

\subsection{Acquisition of triggers}
Advanced LIGO's second observing run O2 lasted $38$ weeks~\cite{GWOSC}. The software package, \pycbc~\cite{pycbc_code}, processed the O2 data in 22 time-frames (approximately 2 weeks for one time-frames) and found several gravitational wave events and numerous gravitational wave candidates~\cite{pycbc_og0, pycbc_og1, pycbc_og2, pycbc_og3, pycbc_og4, pycbc_og5, pycbc_og6}. Some candidate events were vetoed to be glitches, while others were rejected due to their low significance. The data is divided into these time-frames because the detector's sensitivity does not stay constant throughout the eight-month-long observing period.

In addition to finding candidate events, \pycbc also identified several million background triggers for each time-frame, by searching background data manufactured by time-sliding data within that time-frame. The background triggers help quantify the candidate events' significance for the respective time-frames. Finally, to test the search's sensitivity, \pycbc produced and searched for thousands of simulated signals. 

For our study, we filter the background, simulated and candidate events to include only high-mass events with masses in the ranges of the parameters presented in Table~\ref{tab:parameters}. A plot of the \pycbc triggers from one time-frame, during April 23 - May 8, 2017, is presented in Figure~\ref{fig:templateBank}. This figure also depicts the gravitational wave templates used during the search through this time-frame of data. 


\begin{table}[t]

\caption[BBH parameters corresponding to duration $<454\ \text{ms}$]{\label{tab:parameters}Template Banks's parameters for templates with duration $<454 \ \text{ms}$.}
\centering
\begin{tabular}{lrr}
\toprule
  & Minimum & Maximum\\
\midrule
Component Mass 1 [\msun] & 31.54 & 491.68\\
Component Mass 2 [\msun] & 1.32 & 121.01\\
Total Mass [\msun] & 56.93 & 496.72\\
Chirp Mass [\msun] & 8.00 & 174.56\\
Mass Ratio & 0.01 & 0.98\\
\end{tabular}
\end{table}



\begin{figure*}[!ht]

{\centering \includegraphics[width=0.75\linewidth]{images/template_bank.png}

}
% time for chunk 14
% 1176955218, Apr 23, 2017, 4:00 UTC
% 1178294418, May 08, 2017, 16:00 UTC
\caption[High-mass BCR search space.]{The template bank (pink) used by \pycbc to search a section of O2 data from $\text{April 23 - May 8, 2017}$. Our search is constrained to the high-mass parameter space enclosed by the dashed line. The candidate, background and simulated triggers detected in this region of the parameter space during this period are plotted in orange, grey and blue respectively.  }\label{fig:templateBank}
\end{figure*}


\subsection{Calculating the BCR for triggers}
To evaluate $Z^S$, $Z^G_i$ and $Z^N_i$ as shown in Eqs.~\ref{eq:zn}-\ref{eq:zg} and calculate the \bcr Eq.~\ref{eq:bcr} for these triggers, we carry out Bayesian inference with \bilby~\cite{bilby}, employing \dynesty~\cite{dynesty} as our nested sampler. Nested sampling, an algorithm introduced by~\citet{skilling2004, skilling2006}, provides an estimate of the true Bayesian evidence and is often utilised for parameter estimation within the LIGO collaboration~\cite{bilby, bilby_paper, pbilby_paper}.

The most computationally intensive step during Bayesian inference is evaluating the likelihood $\mathcal{L}(d_i|\template)$. To accelerate our analysis, we use a likelihood that explicitly marginalises over coalescence time, phase at coalescence, and luminosity distance (Eq.~80 from~\citet{intro_to_gw_bayes}). While this marginalised likelihood reduces the run time without introducing errors to our evidence evaluation, it does not generates samples for the marginalised parameters. However, these parameter samples can be calculated as a post-processing step~\cite{intro_to_gw_bayes}.

We set the priors $\pi(\parameters|\mathcal{H}_S)$ and $\pi(\parameters|\mathcal{H}_G)$ to be identical. These priors restrict signals with mass parameters in the ranges presented in Table~\ref{tab:parameters}. The spins are aligned over a uniform range for the dimensionless spin magnitude from $\left[0,1\right]$. The luminosity distance prior assigns probability uniformly in comoving volume, with an upper cutoff of $5\ \text{Gpc}$. The full list of the priors, along with their shapes, limits and boundary conditions are documented in Table~\ref{tab:priors}. 

\begin{table}
    \centering
    \caption{
    Prior settings for the parameters used during our parameter estimation. The definitions of the parameters are documented in \citet{bilby_gwtc}~Table~E1.\label{tab:priors}}
    \begin{tabular}{c c c c}
    \hline
    Parameter & Shape & Limits & Boundary \\
    \hline
          $\mathcal{M}/\msun$           & Uniform & 7--180 & Reflective \\
          $q$                           & Uniform & 0.1--1 & Reflective \\
          $M/\msun$                     & Constraint & 50--500 & -- \\
          $d_\mathrm{L}/\mathrm{Mpc}$   & Comoving & 100--5000 & Reflective \\
          $a_1$, $a_2$                  & Uniform & 0--1 & Reflective \\
          $\theta_{JN}$                 & Sinusoidal & 0--$\pi$ &  Reflective \\
          $\psi$                        & Uniform & 0--$\pi$ &  Periodic \\
          $\phi$                        & Uniform & 0--$2\pi$ &  Periodic \\
          ra                            & Uniform & 0--$2\pi$ &  Periodic \\
          dec                           & Cosine & 0--$2\pi$ &  Reflective \\
    \hline
    \end{tabular}
\end{table}

The waveform template we utilise is \imrphenomp, a phenomenological waveform template constructed in the frequency domain that models the in-spiral, merger, and ringdown (IMR) of a compact binary coalescence~\citep{khan2016frequency}. Although gravitational wave templates such as \seob~\cite{seobnrv4phm} which incorporate more physics, such as information on higher-order modes, we still use \imrphenomp as it is inexpensive compared to waveforms fitted against numerical-relativity simulations.

We take 31 neighbouring, off-source, non-overlapping,  4-second  segments of time-series data before the analysis data segment $d_i$ to generate the PSD. We use off-source to avoid the inclusion of a signal in the PSD calculation. A Tukey window with 0.2-second roll-offs is applied to each data segment to suppress spectral leakage after which the segments are fast-Fourier transformed and median-averaged to create a PSD~\cite{ligo_psd}. Like other PSD estimation methods, this method adds statistical uncertainties to the PSD~\cite{psd_student_t, chatziioannou2019noise}. To marginalise over the statistical uncertainty, we use the median-likelihood presented by~\citet{psd_student_t} as a post-processing step and shift our Bayesian Evidence estimations closer to their astrophysical values. 

Finally, we neglect detector calibration uncertainty and acquire data from from the Gravitational Wave Open Science Center~\cite{GWOSC}. The data we use is the publicly accessible O2 strain data from the Hanford and Livingston detectors, recorded while the detectors are in ``Science Mode''. We obtain the data using \gwpy~\cite{gwpy}. 

The run-time to calculate a single Bayesian evidence after using \dynesty with $1,000$ live points and $100$ walkers is usually between $1-12\ \text{hours}$ (where the run time is proportional to the SNR of the data segment). \bilbypipe orchestrates the creation of the PSDs and execution of the parameter estimation jobs~\cite{bilby_pipe}.

\subsection{Assigning \pastro to candidate events}
After the calculating the \bcr for the entire set of high-mass background and simulated triggers, we calculate probability distributions $p_b(\bcr)$ and $p_s(\bcr)$ for each 2-week time-frame of O2 data. These distributions are used to obtain the `tuned' prior-odd $\alpha$ and $\beta$ values that maximise $D_{KL}(p_b|p_s)$ for each time-frame of data.

Finally, using the tuned prior odds the \bcr for the candidate events can be calculated. Figure~\ref{fig:bcrCdf} shows the \bcr distributions for the background triggers, simulated triggers and candidate events. The bulk of the background and simulated trigger distributions are separate but slightly overlap due to some of the simulated signal's being very faint. The separation suggests that the \bcr can successfully distinguish signals from noise or glitches. The vertical lines in Figure~\ref{fig:bcrCdf} displays the \bcr for gravitational wave candidate events. On comparing the candidate event \bcr values with the background distribution, we can estimate \pastro values for the candidate events. 

\begin{figure}[!ht]
{\centering \includegraphics[width=0.75\linewidth]{images/bcr_cdf_smaller_legend.png} }
\caption[BCR distribution example]{Histograms represent the survival function (1-CDF) from our high-mass selection of background triggers (grey) and simulated signals (blue) triggers obtained from \pycbc's search of data from $\text{August 13 - 21, 2017}$. Vertical lines mark the $\text{ln}\ \bcr$ of IAS's GW170817 and GWTC-1's GW170814.}\label{fig:bcrCdf}
\end{figure}


\section{\label{sec:Results}Results}

\input{Data/results_table}
We analyse the $60\ 996$ background, $5\ 146$ simulated, and $25$ candidate triggers reported by \pycbc's search of the data from the second observing run, restricting our analysis to the triggers that fall within our Bayesian prior space as described in Section~\ref{sec:method}. In addition to these triggers, we also analyse events and candidate events reported by GWTC-1 and the IAS group (note that some of these were identified as candidates by the \pycbc search). In Table~\ref{tab:results}, we summarise the \pastrobcr, along with the \pastro of other pipelines for comparison. Note that although the various pipeline \pastro are not mathematically equivalent, by comparing pipeline \pastro values for a given event, we can compare how significant each pipeline deems various candidates. The $\alpha$ and $\beta$ values utilised for each time-frame of O2 are reported in Appendix~\ref{apdx:alphabeta}


\subsection{GWTC-1 Events}
All the confirmed gravitational wave events from binary black hole mergers reported in GWTC-1 and within our prior space, (specifically GW170104, GW170608, GW170729, GW170809 and GW170814), have $\pastrobcr$ greater than $0.9$, indicating a high probability of the presence of an astrophysical signal. 

In addition to the above confirmed gravitational wave events from GWTC-1, we have also analysed several candidate events discussed in GWTC-1, most of which have low \pastrobcr. For example, consider the candidate event 170412, assigned a $\pastro$ of $0.06$ by \gstlal and has a $\pastrobcr$ of $0.01$. This candidate was reported to be excess power caused due noise appearing non-stationary between 60-200 Hz~\cite{GWTC1}. This candidate acts as an example of how $\pastrobcr$ may be utilised  to eliminate terrestrial noise sources, in addition to detecting signals

\subsection{IAS Events}
Our analysis of the high-mass IAS events and candidates in O2 has resulted in three events with disfavourable $\pastrobcr<0.5$ (GWC170402, GW170403, GW170425), and four events and one candidate with $\pastrobcr\geq0.5$ (GW170121, 170302, GW170304, GW170727, GW170817A). 

GWC170402, detected by \citet{IAS2}, is reported to have a signal that is not described well by waveforms for circular binaries with aligned spins. Hence, we might have received a low \pastrobcr due to our usage of \imrphenomp, a waveform that does not account for eccentricity. Additionally, the search conducted by \citet{IAS2} was a single-detector search. Our ranking statistic relies on the signal to appear coherent, even if just faintly coherent, amongst the various detectors to have a high \pastrobcr. Hence, the lack of coherence and the non-eccentric waveform may be the leading factors for a low \pastro. GW170403 and GW170425 which have $\pastrobcr<0.35$ also have low  \pastro reported by \citet{pycbc_ogc_2},  suggesting that these events may have been false alarms.

From the candidates with $\pastrobcr>0.5$, GW170727 and 170302 are of particular interest, with \pastrobcr of $0.92$ and $0.63$. GW170727 was emitted from a black hole binary system with a source frame total mass $\approx 70\ \msun$. In addition to the high \pastrobcr reported by our study, \citet{IAS1} and \citet{pycbc_ogc_2} have also reported high \pastro values of 0.98 and 0.99, making it a viable gravitational-wave event candidate. Similarly, the sub-marginal-candidate 170302 reported by \cite{IAS1} with a \pastro of 0.45 appears to have a higher significance from our analysis, resulting in a \pastrobcr of $0.63$.  

% \av{Interesting that GW170817A has high \pastrobcr as IAS2's pipeline works well on single detector events (marginal in other detectors)} 


\subsection{New Candidate Events}
Although no clear detections are made with the \bcr, a marginal-candidate 170222 has been discovered with a $\pastrobcr\sim0.5$. This candidate has its similar masses when compared to those of GWTC-1. The remaining coherent trigger candidates all have $\pastrobcr\ll0.5$ making them unlikely to originate from astrophysical sources. 




\section{\label{sec:Conclusion}Conclusion}

In this paper, we demonstrate that the Bayesian Coherence Ratio~\cite{BCR1} can be used as a ranking statistic to provide a better measure of significance for gravitational wave candidates by re-analysing the significance of high-mass binary black hole triggers from O2. This method takes a step towards building a unified Bayesian framework that provides a search-pipeline agnostic measure of significance, utilising the same level of physical information incorporated during parameter estimation. 

We focused our analysis on the high-mass regime as this region of the parameter space is plagued with a high number of short duration terrestrial artefacts that can mimic signals. In addition to the high-mass triggers, we also analyse the high-mass binary black hole events in O2 reported by LIGO~\cite{GWTC1} and IAS~\cite{IAS1, IAS2}. Using \pastrobcr, we find that the analysed GWTC-1 events have high probabilities of originating from an astrophysical source. We also find that some of the GWTC-1 marginal triggers that have corroborated terrestrial sources (for example candidate 170412) have low \pastrobcr, indicating this method's ability to discriminate between terrestrial artefacts and astrophysical signals. Our analysis on the IAS events has demonstrated that GW17072 is highly likely to originate from an astrophysical source, while GW17040 is not. Finally, we did not identify any new gravitational-wave events, but we did find some a marginal candidate 170222. 

Although our analysis targets high-mass triggers, this method can be extended to include the entire body range of LIGO-detectable gravitational wave sources. Additionally, to further improve the method's infrastructure, we can use more robust gravitational wave templates (such as templates that incorporate higher-order modes), and sophisticated glitch models. Future analysis can also incorporate data from all available detectors in a network to increase the sensitivity of \pastrobcr. The BCR can discern better whether a candidate is a coherent astrophysical candidate or an incoherent glitch with data from more detectors. 

\av{as the core of this method is PE, improvements in PE can be adapted into this method}

%%%%%%---SECTIONS-END---%%%%%%%%%%%%

%%%%%%---ACKNOWLEDGEMENTS---%%%%%%%%%%%%
\begin{acknowledgments}

This research has made use of data, software and/or web tools obtained from the Gravitational Wave Open Science Center (https://www.gw-openscience.org), a service of LIGO Laboratory, the LIGO Scientific Collaboration and the Virgo Collaboration. LIGO is funded by the U.S. National Science Foundation. Virgo is funded by the French Centre National de Recherche Scientifique (CNRS), the Italian Istituto Nazionale della Fisica Nucleare (INFN) and the Dutch Nikhef, with contributions by Polish and Hungarian institutes.


\end{acknowledgments}
%%%%%%%%%%%%%%%%%%%%%%%%

\appendix

\section{Tuned prior odds}\label{apdx:alphabeta}

O2 lasted several months over which the detector's sensitivity varied. Hence, a part of our analysis entailed tuning the prior odds for obtaining a signal and a glitch, $\alpha$ and $\beta$, as described in Section~\ref{sec:method}. Table~\ref{tab:priorodds} presents the signal and glitch prior odds utilised for each time-frame of O2 data. \av{note: havent tuned all chunks yet -- and tbh the 'tuning' could be better, atm brute force searching a 2d log-spce grid}
\input{Data/alpha_beta_table}

Tuning the prior odds can dramatically affect the \pastrobcr. For example, consider Table~\ref{tab:tuningresults}, which reports tuned \pastrobcr and un-tuned \untunedpastrobcr (where $\alpha=1$ and $\beta=1$) for various high-mass events and candidates. By tuning the prior odds, the \pastrobcr for some IAS events (for example, GW170403 and GW170817A) can change by more than 0.5, resulting in the promotion/demotion of a candidate's significance.

\input{Data/tuning_results_table}

\bibliography{high_mass_bib}% Produces the bibliography via BibTeX.

\end{document}
%
% ****** End of file apssamp.tex ******
