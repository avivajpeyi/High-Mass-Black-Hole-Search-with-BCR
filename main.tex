
\documentclass[%
 %reprint,
%superscriptaddress,
%groupedaddress,
%unsortedaddress,
%runinaddress,
%frontmatterverbose, 
preprint,
%preprintnumbers,
%nofootinbib,
%nobibnotes,
%bibnotes,
 amsmath,amssymb,
 aps,
%pra,
%prb,
%rmp,
%prstab,
%prstper,
%floatfix,
]{revtex4}

\usepackage{aas_macros}
\usepackage{amssymb}
\usepackage{amsmath}
\usepackage{array}
\usepackage{graphicx}
\usepackage{color,units}
\usepackage[dvipsnames]{xcolor} % for more colours!

\usepackage{lineno}
\usepackage{xspace}
\usepackage{dcolumn}
\usepackage{longtable}
\usepackage[normalem]{ulem} %% for striking out text
\usepackage{subfigure}
\usepackage[T1]{fontenc}
\usepackage{hyperref}


\usepackage{dcolumn}% Align table columns on decimal point
\usepackage{booktabs}
\usepackage{xspace} 
\usepackage{bm}% bold math
\usepackage{hyperref}% add hypertext capabilities
\usepackage{graphicx} % Include figure files
\graphicspath{{Figures/}} %Setting the graphicspath

                 % Astronomical Journal

\newcommand{\prior}{{\sc prior}\xspace}
\newcommand{\bilby}{{\sc Bilby}\xspace}
\newcommand{\bilbypipe}{{\sc bilby\_pipe}\xspace}
\newcommand{\bilbypipegdb}{\texttt{bilby\_pipe\_gracedb}\xspace}
\newcommand{\pbilby}{{\sc pBilby}\xspace}
\newcommand{\dynesty}{{\sc dynesty}\xspace}
\newcommand{\cpnest}{{\sc cpnest}\xspace}
\newcommand{\ptemcee}{{\sc ptemcee}\xspace}
\newcommand{\gwpy}{{\sc GWpy}\xspace}
\newcommand{\imrphenomp}{{\sc IMRPhenomPv2}\xspace}
\newcommand{\seob}{{\sc SEOBNRv4PHM}\xspace}
\newcommand{\pycbc}{{\sc PyCBC}\xspace}
\newcommand{\bcr}{{\sc BCR}\xspace}
\newcommand{\psd}{{\sc $\sigma^2_i$}\xspace}
\newcommand{\pastro}{{$p_\text{astro}$}\xspace}
\newcommand{\msun}{{M${}_\odot$}\xspace}



\newcommand{\av}[1]{\textcolor{orange}{[AV: #1]}}
\newcommand{\rs}[1]{\textcolor{red}{[RS: #1]}}
\newcommand{\et}[1]{\textcolor{blue}{[ET: #1]}}


\begin{document}

\preprint{APS/123-QED}

\title{A Bayesian search to find \\high-mass black holes in LIGO data}% Force line breaks with \\



\author{Author list TBD}

\date{\today}

\begin{abstract}

The detection of high mass black holes ( $>100$ \msun) will shed light on the formation of supermassive black holes and thus galaxy formation. Although LIGO is sensitive to the merger of binary black holes with total masses up to 500 \msun, the largest total mass detected so far is approximately $80$ \msun. A possible explanation for the absence of high mass events may be due to their misclassification as short-duration instrumental noise transients. Short-duration instrumental transients mimic the short-duration gravitational-wave signals from high-mass binary black hole mergers. Here we demonstrate that a new search method utilising Bayesian inference could be a more sensitive tool for detecting high-mass binary black hole mergers as compared to traditional match-filtering. We have applied this technique on the high-mass triggers during LIGO's second observing run to investigate the possibility of discovering new gravitational-wave signals from an entirely new class of high mass black hole binaries.



\end{abstract}

\maketitle

%\tableofcontents


%%%%%%---SECTIONS---%%%%%%%%%%%%
\section{\label{sec:Introduction}Introduction}

Since the 1970s, there has been an accumulation of evidence for stellar-mass and supermassive black holes. In 2019, the Event Horizon Telescope provided the first visual evidence of the supermassive black hole M87  \cite{m87photo}.  As of January 2020, LIGO, Virgo and IAS have confirmed more than a dozen binary black hole systems \cite{GWTC1, IAS0, IAS1, IAS2, pycbc_ogc_2}. These various discoveries have firmly established the existence of stellar-mass black holes, supermassive black holes and binary black hole systems.  Interestingly, there is still no direct evidence for intermediate-mass black holes, the black holes that lie in between stellar-mass and supermassive black hole systems with masses between $10^2-10^6$ \msun. Thus, the existence of intermediate-mass black holes is still speculative. \\


If intermediate-mass black holes are present, the gravitational waves emitted from the merger of a binary black hole system with at least one intermediate-mass black hole (up to a mass of $400$ \msun) will be detectable by the ground-based gravitational-wave network. Gravitational waves from such systems should occur at a rate of $0-10\text{yr}^{-1}$ \cite{fregeau2006imbhbRatePrediction, mandel2008rates,rodriguez2015bbhRatePredictions}.  However, even after conducting a targeted matched-filter based search for gravitational waves from intermediate-mass black holes the largest total mass detected so far is approximately $80$ \msun \cite{imbhbSearch2014, ligo_imbh_search, abbott2019gwtc}. A possible explanation for the absence of intermediate-mass events may be due to their misclassification as short-duration instrumental noise transients known as glitches \cite{glitch_in_fifth_ligo_run, bayeswave, improving_dq_in_early_runs, ligo_glitch_gw150914, pycbc_short_duration_transients, pe_with_glitch, blip_glitches}. These glitches can mimic astrophysical signals and hence decrease the significance of true gravitational wave events. \\


One method to account for glitches while searching for gravitational waves from coalescing compact binaries is by utilising an astrophysical Bayesian odds  \cite{bci, BCR1, BCR2, bcr_gw151216, bayesian_odds}. A true Bayesian odds calculated without using bootstrap techniques can provide events with a more accurate significance that is agnostic to a specific search strategy \cite{BCR2, bcr_gw151216,  bayesian_odds}. Additionally, a Bayesian odds can include information such as if the gravitational wave event's signal is coherent amongst the network of detectors, if the binary system that created the gravitational waves was precessing, and if the gravitational wave signal contains higher-order modes.  It is because Bayesian methods can incorporate all this physical information about a gravitational wave signal that the LIGO Scientific Collaboration uses these methods to determine the source parameters of gravitational wave events \cite{abbott2016ligo, abbott2019gwtc}. This paper demonstrates that the power of Bayesian methods used in parameter estimation can also successfully be used to discriminate between coherent gravitational-wave signals, incoherent glitches, and Gaussian noise in the form of a Bayesian search. \\

In this paper we utilise a Bayesian method, called the \bcr \cite{BCR1}, to search for the significant gravitational wave signals from high-mass (systems with total masses in the range of $55-500$ \msun) compact binary coalescences in the detector data recorded during aLIGO's second observing run (O2).  We find that (a) our search does not identify any unreported stellar mass or intermediate mass black holes; (b) high-mass events reported in the GWTC-1, including GW170729 (an event with disputed $p_\text{astro}$ amongst various search pipelines) have high low significance; and that (c) high-mass events detected from some independent groups have low significance. \\

The remainder of this paper is structured as follows. We outline our analysis methods, including details of the \bcr in Section~\ref{sec:method}. We present our results in Section~\ref{sec:result}, and discuss these results in the context of the significance of gravitational wave candidates in Section~\ref{sec:Conclusion}.


\section{Method\label{sec:method}}

\av{I have broken this section up into subsections for my convenience, we can remove them later}

\subsection{The Bayesian Coherence Ratio}

Following \citet{BCR1}, the \bcr is an odds ratio of the coherent signal hypotheses $\mathcal{H_S}$ and the incoherent instrumental feature hypothesis $\mathcal{H_I}$ for a network of $D$ detectors. $\mathcal{H_I}$ states that each $i$th detector has either pure Gaussian noise $\mathcal{H_N}$ or a glitch $\mathcal{H_G}$. The \bcr is given by
\begin{equation}
BCR = \frac{\alpha Z^S}{\prod\limits^D_{i=1}[\beta Z^G_i + (1-\beta)Z^N_i]}\ ,
\end{equation}
where $Z^S$, $Z^G_i$ and $Z^N_i$ are the Bayesian evidences (marginalised likelihoods) for $\mathcal{H_S}$, $\mathcal{H_N}$, and $\mathcal{H_G}$. $\alpha$ and $\beta$, are the prior odds for obtaining a signal $\alpha=P(\mathcal{H_S})/P(\mathcal{H_I})$ and the prior odds for obtaining a glitch $\beta=P(\mathcal{H_G})/P(\mathcal{H_I})$. As the rate of signal and glitches are unknown, these priors $\alpha$ and $\beta$ are tuned to maximise the \bcr distributions for background data (signal-free data) and simulated signals \cite{BCR1}.  \\

\subsection{Bayesian Evidence Evaluation}
\subsubsection{Noise Model}
We assume that each detector's noise is Gaussian and stationary over the period being analysed \cite{ligo_psd}. In practice, we estimate the noise using a noise power spectral density \psd for each of the $i$ detectors. \\

To generate the \psd, we take 31 neighbouring, ``off-source'', non-overlapping,  $4\ s$  segments of time-series data prior to the data segment $d_i$ being analysed. A Tukey window with a roll off of $0.2\ \text{s}$ is applied to each data segment to suppress spectral leakage after which the segments are fast-Fourier transformed and median-averaged to create a \psd \cite{ligo_psd}. This method, like other \psd estimation methods, adds statistical uncertainties to the \psd \cite{psd_student_t}. To marginalise over the statistical uncertainty we use the median-likelihood presented by \citet{psd_student_t} as a post-processing step and shift our Bayesian Evidence estimations closer to their true astrophysical values.

Using the \psd, for each data segment $d_i$ in each of the $i$ detectors in a network of $D$ detectors, we can write 
\begin{equation}
Z^N_i =  \frac{1}{2\pi \sigma^2_i} \text{exp}\left(-\frac{1}{2} \frac{d_i}{\sigma^2_i} \right) .
\end{equation}

\subsubsection{Coherent Signal Model}
We model coherent signal using a binary black hole waveform template $\mu(\vec{\theta})$, where the vector $\vec{\theta}$ contains a point in the 15 dimensional space describing precessing binary-black hole mergers. For the signal to be coherent, $\vec{\theta}$ must be consistent in each $4\ \text{s}$ data segment $d_i$ for a network of $D$ detectors, Hence, the coherent signal evidence is calculated as
\begin{equation}
\label{eq:zs}
Z^S = \int\limits_{\vec{\theta}} \prod\limits^{D}_{i=1} \left[\frac{1}{2\pi \sigma^2_i} \text{exp}\left(-\frac{1}{2} \frac{(d_i-\mu(\vec{\theta}))^2}{\sigma^2_i} \right) \right] \pi(\vec{\theta}| \mathcal{H_S})\  \text{d}\vec{\theta} \ ,
\end{equation}
where $\pi(\theta| \mathcal{H_S})$ is the prior for the parameters in the coherent signal hypothesis. 

\subsubsection{Incoherent Glitch Model}
Finally, as glitches are challenging to model and poorly understood, we utilise a surrogate model for glitches: the glitches are modelled using $\mu(\vec{\theta})$ with uncorrelated  parameters amongst the different detectors such that  $\vec{\theta}_i \neq \vec{\theta}_j$ for two detectors $i$ and $j$ \cite{bci}.  Modelling glitches with gravitational wave templates captures the worst case scenario for when glitches appear similar to gravitational wave signals. Thus, we can write $Z^G_i$ as 
\begin{equation}
\label{eq:zg}
Z^G_i = \int\limits_{\vec{\theta}} \frac{1}{2\pi \sigma^2_i} \text{exp}\left(-\frac{1}{2} \frac{(d_i -\mu(\vec{\theta}))^2}{\sigma^2_i} \right) \pi(\vec{\theta}| \mathcal{H_G})\  \text{d}\vec{\theta}  \ ,
\end{equation}
where $\pi(\theta| \mathcal{H_G})$ is the prior for the parameters in the incoherent glitch hypothesis. 





\section{Analysis}\label{sec:Analysis}

Advanced LIGO's second observing run O2 lasted $38$ weeks \cite{GWOSC}. The software package, \pycbc \cite{pycbc_code}, processed the O2 data in 22 chunks (approximately 2 weeks for one chunk) and found several gravitational wave events and some gravitational wave candidates \cite{pycbc_og0, pycbc_og1, pycbc_og2, pycbc_og3, pycbc_og4, pycbc_og5}.  

At its core, \pycbc performs a matched-filter search for binary merger signals using a template-bank of gravitational-wave template waveforms to generate triggers. For the trigger to be considered a \textbf{candidate trigger} by \pycbc, it must be observed between detectors with the same template and with a time of arrival difference less than the gravitational-wave travel time between detectors \cite{pycbc_og0}. To test its search, \pycbc also conducts searches for simulated signals. \textbf{Simulated triggers} are artificial triggers created by injecting signals into the detector data. These simulated signal studies provides \pycbc with metrics on its sensitivity. Finally, to quantify the rareness of candidate events, \pycbc artificially constructs a \textbf{background trigger} set to compare the candidate events against. These background triggers are signal-free events, created by applying relative offsets, or time-shifts, between the data of different detectors \cite{pycbc_og0}. Note that the time-shifts are greater than the gravitational-wave travel time between detectors.  

The \pycbc search in O2 produced numerous candidate, simulated and background triggers. For our high-mass study, we screen the triggers to only allow
triggers with masses within the ranges of the parameters presented in Table\textasciitilde\ref{tab:parameters}. Plot of the \pycbc triggers from one chuk  To calculate the \bcr for these triggers, we carry out Bayesian inference with \bilby \cite{bilby}, employing \dynesty \cite{dynesty} as our nested sampler. Nested sampling, an algorithm introduced by \cite{skilling_nested_sampling}, provides an estimate of the true Bayesian evidence and is often utilised for parameter estimation within the LIGO collaboration \cite{bilby}.

We restrict the priors for Bayesian inference on the masses to only consider signals shorter than $454 \text{ms}$ in duration, as presented in Table\textasciitilde\ref{tab:parameters}. The spins are set to be aligned with a uniform range for the dimensionless spin magnitude from $\left[0,1\right]$. The prior on luminosity distance assigns probability uniformly in comoving volume, with an upper cutoff of $5\ \text{Gpc}$. We implement the same priors as used in GWTC-1 for the remaining parameters. The priors we use for the coherent signal and incoherent glitch hypotheses are identical.\\

The waveform template we utilise is \imrphenomp $\mu_{\text{IMR}}(\vec{\theta})$, a phenomenological waveform template constructed in the frequency domain that models the in-spiral, merger, and ringdown (IMR) of a compact binary coalescence \citep{khan2016frequency}. Although gravitational wave templates such as \seob \cite{seob} created from numerical relativity simulations incorporate more physics such as information on higher-order modes, we still use $\mu_{\text{IMR}}(\vec{\theta})$ as it evaluates faster than numerical relativity models. 

Finally, we neglect detector calibration uncertainty and acquire data from from the Gravitational Wave Open Science Center \cite{GWOSC}. The data we use is the publicly accessible O2 strain data from the Hanford and Livingston detectors. To ensure the data is usable we verify that the analysis and PSD data are obtained when the detectors are  in ``Science Mode''. The data requisition and quality checks are conducted using \gwpy \cite{}. 

For the Bayesian Inference, we use a ? likelihood.... \av{talk about TDP marginalisation, cite Eric and COlms paper}


The run-time for to calculate a single Bayesian evidence after using \dynesty with $1,000$ live points and $100$ walkers is usually between $0.5-12\ \text{hours}$ (where the speed often depends on the SNR of the data segment). 





 

\pastro, the probability that a signal is of astrophysical origin \cite{pastro_1,pastro_2,pastro_3},

 provides a Bayesian odds ratio comparing the probability that the data contains an astrophysical signal versus the probability that the data contains an incoherent glitch or noise. Although an odds ratio, the \bcr can be used  as a frequentistic \textit{ranking statistic}, ranking the likelihood that a trigger is due to a gravitational-wave signal \cite{BCR}. The \bcr as a ranking statistic is much more powerful than a matched-filter SNR as the \bcr incorporates numerous features that may distinguish gravitational waves from noise and demands that signals must be coherent while glitches must be incoherent amongst different detectors. \\

 

% PyCBC asks for the 5 citations:
% http://pycbc.org/pycbc/latest/html/credit.html#searches-for-compact-binary-coalescence
high-mass candidate events, simulated signal events and  background events (signal-free events ) supplied by the \pycbc \cite{pycbc_code} search in O2  \


Figure~\ref{fig:templateBank} depicts the \pycbc template bank, the high-mass search space and the candidate events, simulated events and background events from a one-week stretch of \pycbc's search in O2. 

Week long stretches of analysis because noise-non stationary, glitches will occur at different rates depending on state of detectors 


Dont know the prior odds, 




\hypertarget{trigger-sets-for-bcr-analysis}{%
\subsection{Trigger sets for BCR analysis}\label{trigger-sets-for-bcr-analysis}}

We calculate the BCRs using the procedure described above for three separate trigger sets: background triggers,
foreground triggers, and software injections. The software injections created using masses, spins and distances that
span our priors. The software injections are inserted in the O2 data from where the other triggers are retrieved.

We expect the background trigger BCRs to favour the incoherent glitch hypothesis, and the software injection BCRs to
favour the coherent, compact binary coalescence hypothesis. The foreground trigger BCRs should fall along with the
background if the foreground trigger is a glitch, and with the software injections if the foreground trigger is a
gravitational wave candidate. For example, consider Figure\textasciitilde\ref{fig:bcrIfar} that contains a plot of the BCRs for
several O1 background triggers, foreground triggers, and software injections plotted against iFAR (inverse
false-alarm-rate). In the figure, some foreground triggers fall along the background distribution, these are discarded
as glitches. The foreground triggers that fall along the bulk of software injections are considered gravitational wave
candidates.



\begin{figure}[!h]

{\centering \includegraphics[width=0.75\linewidth]{images/bcr_ifar} 

}

\caption[BCR vs iFAR for O1]{BCR versus iFAR distributions from simulated signals (blue), hardware injections (green), GW events (stars) and background triggers (black), taken from \citet{BCR1}.}\label{fig:bcrIfar}
\end{figure}

\hypertarget{making-a-significance-statement}{%
\subsection{Making a significance statement}\label{making-a-significance-statement}}

After obtaining the BCRs for the foreground triggers, background triggers, and software injections, we can make a
statement about the significance of foreground events. For example, consider Figure\textasciitilde\ref{fig:bcrCdf} which displays ln
BCR distributions obtained from our BCR pipeline for aLIGO O2 PyCBC chunk three background triggers and software injections.
The figure also displays the ln BCR values obtained for four foreground triggers. The two foreground triggers with low
ln BCRs are confirmed glitches. The rightmost foreground trigger is GW170104, a gravitational wave event confirmed by
LIGO, and shows much stronger evidence for it being a coherent, compact binary coalescence signal, rather than it being
an incoherent glitch. The remaining foreground trigger corresponds to a gravitational wave candidate identified by the
IAS group.



\begin{figure}[!h]

{\centering \includegraphics[width=0.75\linewidth]{images/bcr_cdf} 

}

\caption[BCR distribution example]{Histograms represent the survival function (1-CDF) from our selection of 2407 aLIGO O2 PyCBC chunk 3 background triggers (gray) and 648 simulated signals (blue). Vertical lines mark the ln BCRs of two glitches (orange and yellow), IAS's GW170121 (pink), and GWTC-1's GW170104 (dark blue).}\label{fig:bcrCdf}
\end{figure}

Irrespective of the BCR's Bayesian interpretation, we may treat the BCR as a traditional detection statistic to obtain a
frequentist estimate of the significance of any given foreground event based on the measured background with a p-value.
The p-value of foreground events can be obtained from the background's survival function. For example, in
Figure\textasciitilde\ref{fig:bcrCdf}, the p-value for GW170104 is 0.99, denoting that it is significantly different from the bulk
of the background distribution and hence likely to have astrophysical origins. On the other hand, the p-value for the
IAS candidate is 0.65, demonstrating that this candidate might be a glitch.

To calculate the p-value, we need first to calculate fits to the BCR probability
distributions and then tune the BCR's parameters. The following subsections describe these calculations.

\hypertarget{fitting-bcr-data}{%
\subsubsection{Fitting BCR data}\label{fitting-bcr-data}}

Although the BCR should favour the coherent signal hypothesis for software injections,
software injections with a very low SNR might not look coherent amongst an ensemble of
detectors. Hence, software injections are likely to have two probability distributions
of BCRs, one probability distribution of low BCRs corresponding to the software
injections that have very low SNRs and another probability distribution of software
injections with high BCRs. Due to this, we use Gaussian mixture models with two Gaussian
components to fit our BCR distributions.

\hypertarget{tuning-of-bcr-using-kl-distance}{%
\subsubsection{Tuning of BCR using KL Distance}\label{tuning-of-bcr-using-kl-distance}}

The BCR has two tunable parameters as described in Section\textasciitilde\ref{bcrCalculation},
\(\alpha\) and \(\beta\). Altering \(\alpha\) translates the BCR probability distributions for
the triggers while adjusting \(\beta\) spreads the probability distributions out. Although
Bayesian hyper-parameter estimation might be able to determine the optimal values for
these parameters, an easier approach is to manually adjust the parameters for each data
chunk's BCR distribution. In this study, we manually adjust \(\alpha\) and \(\beta\) to
maximally separate the BCR distributions for the software injections and background
triggers.

To calculate the separation between the background and software injection BCR
distributions, we use the Kullback--Leibler divergence (also called relative entropy, or
KL divergence) to quantify how different how the background and software injection BCR
probability distributions are. If the distributions are identical, the KL divergence is
equal to 0, and the KL divergence increases as the asymmetry between the distributions
increases. Figure\textasciitilde\ref{fig:klDivGrid} displays a contour plot of O2 Chunk 14's KL
divergences between the background and software injection triggers for values of
\(\alpha\) and \(\beta\) ranging from \(1^{-10}\) to \(1\). We select these ranges for \(\alpha\)
and \(\beta\) as values outside this range will not make physical sense. Note that for a
fixed value of \(\beta\), the KL divergence stays the same as we alter \(\alpha\). This is
because \(\alpha\) translates the BCR values, but does not alter the distributions
themselves.



\begin{figure}[!h]

{\centering \includegraphics[width=0.75\linewidth]{images/kl_divergence_grid} 

}

\caption[KL Divergence grid for both BCR tunable parameters]{KL Divergences for O2 Chunk 14's software injection and background trigger BCR probability distributions. The red line indicates the \(\alpha\) and \(\beta\) parameters with the maximum KL divergence in this range of \(\alpha\) and \(\beta\).}\label{fig:klDivGrid}
\end{figure}

Figure\textasciitilde\ref{fig:klDivLine} displays a plot of O2 Chunk 14's KL divergences only as
\(\beta\) is adjusted for a fixed \(alpha=1^{-6}\). The \(\alpha\) and \(\beta\) are then selected
based on the combination that results with the maximum KL divergence.



\begin{figure}[!h]

{\centering \includegraphics[width=0.75\linewidth]{images/kl_distance_14} 

}

\caption[KL  Divergences for one BCR tunable parameter]{KL Divergences for O2 Chunk 14's software injection and background trigger BCR probability distributions with \(alpha=1^{-6}\).}\label{fig:klDivLine}
\end{figure}

In Chapter\textasciitilde\ref{progress} we present some of the preliminary BCR search results we
have obtained from the analysis of various O2 data chunks.








In aLIGO's first two observing runs, eleven gravitational wave events were found in the data by the LIGO-Virgo
scientific collaboration \citep{abbott2019gwtc}. Since the public release of LIGO's first and second observing run's data,
several groups have searched the data for gravitational waves independently of LIGO. One particular research group of
interest is a research team at the Institute for Advanced Study (IAS). The group constructed searches to look for the
LIGO-confirmed the gravitational wave events detected by the LIGO-Virgo collaboration, and in the process of doing so,
claim to have discovered several others events \citep{IAS0, IAS1, IAS2}. Some of these events have total masses \(>85 M_{\odot}\), which is larger than the average total mass of the LIGO detections. Some of these IAS and LIGO events are
displayed in Table\textasciitilde\ref{tab:O2significancesWObcr} with their p-astro reported by various LIGO and IAS search pipelines.

\begin{table}[t]

\caption[p-astro for various O2 foreground triggers]{\label{tab:O2significancesWObcr}p-astro from several detection pipelines for a subset of the O2 foreground triggers.}
\centering
\begin{tabular}{llrrrr}
\toprule
Event & Catalogue & PyCBC & GstLAL & cWB & IAS\\
\midrule
GW170104 & GWTC-1 & 1.00 & 1.00 & 1.00 & 0.99\\
GW170121 & IAS-1 & NA & NA & NA & 0.99\\
GWC170402 & IAS-2 & NA & 0.09 & NA & 0.68\\
GW170403 & IAS-1 & NA & NA & NA & 0.56\\
IMBHC170423 & IMBH-marginal & NA & 0.00 & 1.00 & NA\\
GW170425 & IAS-1 & NA & NA & NA & 0.77\\
GW170729 & GWTC-1 & 0.52 & 0.98 & 0.94 & NA\\
\end{tabular}
\end{table}

From this Table\textasciitilde\ref{tab:O2significancesWObcr}, it is evident there is some uncertainty if these events can be considered real
gravitational-wave events -- are these events significantly different from the background or not? The various pipelines
have different answers. Our Bayesian search pipeline, as described in the next section, can help us answer this question
and come to a conclusion about the significance of the events.

\begin{figure}[!h]

{\centering \includegraphics[width=0.75\linewidth]{images/O2_unfiltered_trigger_counts} 

}

\caption[Count of all triggers in PyCBC O2 search]{Counts of triggers from \texttt{PyCBC}'s search through O2 Data (November 15, 2016 - August 26, 2017). Each chunk is roughly 8 days long. The background triggers are collected from timesliding each chunk's data to generate a dataset of roughly 3 million years.}\label{fig:o2TrigCount}
\end{figure}


\begin{table}[t]

\caption[BBH parameters corresponding to durations $<454$ ms]{\label{tab:parameters}Template Banks's parameters for templates with duration $<454$ ms.}
\centering
\begin{tabular}{lrr}
\toprule
  & Minimum & Maximum\\
\midrule
Component Mass 1 $[\text{M}_{\odot}]$ & 31.54 & 491.68\\
Component Mass 2 $[\text{M}_{\odot}]$ & 1.32 & 121.01\\
Total Mass $[\text{M}_{\odot}]$ & 56.93 & 496.72\\
Chirp Mass $[\text{M}_{\odot}]$ & 8.00 & 174.56\\
Mass Ratio & 0.01 & 0.98\\
\end{tabular}
\end{table}



\begin{figure}[!h]

{\centering \includegraphics[width=0.75\linewidth]{images/template_bank_masses} 

}

\caption[High-mass BCR search space.]{The template bank used by \href{https://pycbc.org/}{\texttt{PyCBC}} to search in O2's chunk 14. Our search is constrained to the high-mass parameter space enclosed by the dashed line (triggers with duration \(<45s\).}\label{fig:templateBank}
\end{figure}


\section{\label{sec:Results}Results}
blah



\section{\label{sec:Conclusion}Conclusion}
The detection of high mass black holes (\(>100\) M\({}_\odot\)) will shed light on the formation of globular clusters,
supermassive black holes and thus galaxy formation \citep{lodato2006supermassive, 2018IMBHreview}. LIGO is theoretically
sensitive to the merger of binary black holes with total masses up to 500 M\({}_\odot\) which are expected to occur at a
rate of 0-10 yr\(^{-1}\) \citep[\citet{mandel2008rates}]{fregeau2006imbhbRatePrediction}. However, even after \citet{salemi2019search}'s
targeted match-filter based search for gravitational waves from high-mass black holes the largest total mass detected so
far is approximately 80 M\({}_\odot\) \citep{abbott2019gwtc}. A possible explanation for the absence of high mass events may be
due to their misclassification as short-duration instrumental noise transients \citep{blipGlitches}. High-mass mergers have
very few in-band wave cycles, and hence can easily be mistaken for short-duration instrumental transients. 

We start by developing a targeted search for gravitational waves from high-mass black hole systems. This new targeted
search utilises Bayesian inference and thus is a more sensitive tool for detecting high-mass binary black hole mergers
as compared to traditional match-filtering searches. We have applied this technique on the high-mass triggers during
LIGO's second observing run to investigate the possibility of discovering new gravitational-wave signals from an
entirely new class of high mass black hole binaries.
%%%%%%---SECTIONS-END---%%%%%%%%%%%%

%%%%%%---ACKNOWLEDGEMENTS---%%%%%%%%%%%%
\begin{acknowledgments}
Helpful comments, OzGrav, LIGO, NSF.

This research has made use of data, software and/or web tools obtained from the Gravitational Wave Open Science Center (https://www.gw-openscience.org), a service of LIGO Laboratory, the LIGO Scientific Collaboration and the Virgo Collaboration. LIGO is funded by the U.S. National Science Foundation. Virgo is funded by the French Centre National de Recherche Scientifique (CNRS), the Italian Istituto Nazionale della Fisica Nucleare (INFN) and the Dutch Nikhef, with contributions by Polish and Hungarian institutes.

\end{acknowledgments}
%%%%%%%%%%%%%%%%%%%%%%%%



\bibliography{high_mass_bib}% Produces the bibliography via BibTeX.

\end{document}
%
% ****** End of file apssamp.tex ******
